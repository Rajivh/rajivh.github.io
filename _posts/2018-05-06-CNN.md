A very high level view of CNN - still some holes need to be plugged.

Convolutional neural network is specifically designed for image recognition.
A regular neural network for image recognition has fully connected layers. For instance, consider a 28 * 28 colour image, there will be 28 * 28 * 3 input features and each hidden layer neuron will have 2352 connections (and that many weights).

In a convolutional neural network, the input features are converted to a matrix format and another smaller matrix (with weights) is slid (sideways) over the input matrix - n columns at a time - and slide downwards - n rows at a time. This 'n' is the stride length and is pre defined. Let us call this smaller matrix a filter.

When the smaller matrix slides over, element wise matrix multiplication is done over the input and weights in the filter to get the convolved feature or feature map each value in this feature map is mapped to a hidden neuron.

The filter, as it moves over the input space - retains the same weights - called the shared weights. In effect, it captures the same set of features over the entire input space.

My doubt is - lets assume our input matrix is 28 * 28, the filter is 5 * 5, and the stride length is 1 - then the convolved feature will be of dimension 24 * 24 values. These can be thought of as the matrix of hidden layer (or the convolutional layer) neurons. This feature map will extract one particular feature (spread spatially) from the entire input space.

Similarly, we might need multiple such feature maps to extract different features from the input space. These feature maps will differ in their weights.

The network actually learns these weights (of the different feature maps) during the training process.

Some of the parameters to be set:
Stride Length
Depth - this is the number of feature maps to be created.
Zero padding - Not understood??


A non linear activation function (ReLU mostly) is applied on the convolved feature layer.

The next step is Pooling - Pooling can be seen as considering the highest activation for every subset of the convolved feature map. For instance, each of our convolved feature map is a 24*24 matrix. Let us consider every non overlapping 2*2 matrix and take only the highest activation value and populate these highest values in a pooled layer. We will end up with a pooled layer which is of dimension 12*12 for each feature map. The pooled layer can be thought of as a condensed feature map.

Pooling helps in reducing the 
- feature dimension - converting the input image into a much smaller subset
- helps in feature identification irrespective of the position of the feature in the image - ?? (HOW)
- makes the system immune to image distortion - as we take the maximum activation in a small area (2*2 in this case), a distortion resulting in change within this neighborhood will not change the pooling layer.
- reduces the number of parameters/ connections required

This pooling layer is then fully connected to the next layer. We then use gradient descent/ back propagation to keep adjusting the weights and learn.

